{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amit-Jindar/AyurGenix/blob/main/AyurGenix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scalp Classification Model**"
      ],
      "metadata": {
        "id": "icqw0pV7j3r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_folder = \"/content/drive/MyDrive/dataset\"\n",
        "\n",
        "# Step 2: Load and preprocess images efficiently\n",
        "def load_images_from_folder(folder, img_size=(160, 160)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_dict = {}\n",
        "    class_idx = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        if not files:\n",
        "            continue\n",
        "        class_name = os.path.basename(root)\n",
        "        if class_name not in class_dict:\n",
        "            class_dict[class_name] = class_idx\n",
        "            class_idx += 1\n",
        "\n",
        "        for filename in files:\n",
        "            img_path = os.path.join(root, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                print(f\"Warning: Unable to read image {img_path}\")\n",
        "                continue\n",
        "            img = cv2.resize(img, img_size)\n",
        "            images.append(img)\n",
        "            labels.append(class_dict[class_name])\n",
        "\n",
        "    return np.array(images, dtype=np.float32), np.array(labels, dtype=np.int32), class_dict\n",
        "\n",
        "# Load dataset\n",
        "images, labels, class_dict = load_images_from_folder(dataset_folder)\n",
        "\n",
        "# Print class distribution\n",
        "print(\"Class Distribution:\", np.bincount(labels))\n",
        "\n",
        "# Normalize images\n",
        "images = images / 255.0\n",
        "\n",
        "# Free up memory\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "# Step 3: Use tf.data for efficient processing\n",
        "def preprocess_image(image, label):\n",
        "    return tf.image.resize(image, (160, 160)), label\n",
        "\n",
        "# Split dataset properly using train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow dataset\n",
        "batch_size = 64\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(preprocess_image).batch(batch_size).cache().repeat().prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).map(preprocess_image).batch(batch_size).cache().repeat().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Step 4: Optimized Data Augmentation\n",
        "data_augmentation = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Step 5: Define CNN model with EfficientNetB3 (Optimized for Memory)\n",
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(160, 160, 3))\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze first 100 layers\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(160, 160, 3)),\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    BatchNormalization(),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dropout(0.4),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dropout(0.4),\n",
        "    Dense(len(class_dict), activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 6: Compile model with improved optimizer\n",
        "optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Enable automatic checkpoint saving\n",
        "checkpoint_path = \"/content/drive/MyDrive/hair_loss_model_checkpoint.keras\"\n",
        "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# Reduce RAM usage by enabling garbage collection\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Reduce Learning Rate on Plateau\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=1e-6)\n",
        "\n",
        "# Learning rate warm-up\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr * 1.2\n",
        "    else:\n",
        "        return lr * 0.9\n",
        "\n",
        "lr_warmup = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Enable TensorFlow mixed precision for efficiency\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Train with optimized settings\n",
        "steps_per_epoch = len(X_train) // batch_size\n",
        "val_steps = len(X_val) // batch_size\n",
        "\n",
        "model.fit(train_dataset, validation_data=val_dataset, epochs=30, steps_per_epoch=steps_per_epoch, validation_steps=val_steps, callbacks=[checkpoint_callback, early_stopping, lr_scheduler, lr_warmup])\n",
        "\n",
        "# Evaluate model accuracy\n",
        "val_loss, val_accuracy = model.evaluate(val_dataset, steps=val_steps)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "print(\"Model training completed and best version saved!\")"
      ],
      "metadata": {
        "id": "-vC3PU8foUF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HairFall Prediction Model**\n"
      ],
      "metadata": {
        "id": "6vRS9HqsjIXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "import joblib\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Ensure necessary libraries are installed\n",
        "!pip install tensorflow pandas numpy scikit-learn imbalanced-learn joblib optuna xgboost lightgbm\n",
        "\n",
        "def mount_drive():\n",
        "    drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "def load_image_model(model_path):\n",
        "    if os.path.exists(model_path):\n",
        "        model = load_model(model_path)\n",
        "        print(\"Loaded pre-trained image classification model.\")\n",
        "        return model\n",
        "    else:\n",
        "        print(\"Model checkpoint not found! Please train the image classification model first.\")\n",
        "        return None\n",
        "\n",
        "def optimize_hyperparams(trial, X_train, y_train, X_val, y_val):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 200, 400),\n",
        "        'max_depth': trial.suggest_int('max_depth', 6, 12),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 50),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
        "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 1.0),\n",
        "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 1.0)\n",
        "    }\n",
        "    model = lgb.LGBMClassifier(**params, n_jobs=-1)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "    return accuracy_score(y_val, y_pred)\n",
        "\n",
        "def train_hair_fall_prediction(model_save_path, dataset_path):\n",
        "    questionnaire_data = pd.read_csv(dataset_path)\n",
        "    questionnaire_data.columns = questionnaire_data.columns.str.strip()\n",
        "\n",
        "    if 'Hair Loss' not in questionnaire_data.columns:\n",
        "        raise KeyError(\"Column 'Hair Loss' not found in dataset. Check column names:\", questionnaire_data.columns)\n",
        "\n",
        "    X = questionnaire_data.drop(columns=['Hair Loss'])\n",
        "    y = questionnaire_data['Hair Loss']\n",
        "    X = pd.get_dummies(X, drop_first=True)\n",
        "    y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    if len(np.unique(y)) > 1:\n",
        "        try:\n",
        "            smote = SMOTE(random_state=42, sampling_strategy=\"auto\")\n",
        "            X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "        except ValueError:\n",
        "            print(\"SMOTE failed, switching to SMOTETomek.\")\n",
        "            smote_tomek = SMOTETomek(random_state=42)\n",
        "            X_resampled, y_resampled = smote_tomek.fit_resample(X_scaled, y)\n",
        "    else:\n",
        "        print(\"Skipping SMOTE due to insufficient class variance.\")\n",
        "        X_resampled, y_resampled = X_scaled, y\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    best_model = None\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for train_index, val_index in skf.split(X_resampled, y_resampled):\n",
        "        X_train, X_val = X_resampled[train_index], X_resampled[val_index]\n",
        "        y_train, y_val = y_resampled[train_index], y_resampled[val_index]\n",
        "\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(lambda trial: optimize_hyperparams(trial, X_train, y_train, X_val, y_val), n_trials=10)\n",
        "\n",
        "        best_params = study.best_params\n",
        "        lgb_model = lgb.LGBMClassifier(**best_params, n_jobs=-1)\n",
        "        rf_model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "\n",
        "        stack_model = StackingClassifier(\n",
        "            estimators=[('lgb', lgb_model), ('rf', rf_model)],\n",
        "            final_estimator=lgb.LGBMClassifier(n_jobs=-1)\n",
        "        )\n",
        "\n",
        "        stack_model.fit(X_train, y_train)\n",
        "        y_pred = stack_model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = stack_model\n",
        "\n",
        "        print(f\"Stacking Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    print(f\"Best Model Accuracy: {best_accuracy * 100:.2f}%\")\n",
        "    joblib.dump(best_model, model_save_path)\n",
        "    print(f\"Hair Fall Prediction model saved at {model_save_path}\")\n",
        "    return best_model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mount_drive()\n",
        "    model_path = \"/content/drive/MyDrive/hair_loss_model_checkpoint.keras\"\n",
        "    hair_fall_model_path = \"/content/drive/MyDrive/hair_fall_prediction_model.pkl\"\n",
        "    dataset_path = \"/content/drive/MyDrive/Predict Hair Fall.csv\"\n",
        "\n",
        "    image_model = load_image_model(model_path)\n",
        "    hair_fall_model = train_hair_fall_prediction(hair_fall_model_path, dataset_path)\n"
      ],
      "metadata": {
        "id": "X9wi65cYnHB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recommendation Engine**"
      ],
      "metadata": {
        "id": "Fx_da6d3i0nJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load questionnaire predictions\n",
        "csv_file = \"/content/drive/MyDrive/Predict Hair Fall.csv\"\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Define scalp classification folder structure\n",
        "scalp_folder = \"/content/drive/MyDrive/Scalp\"\n",
        "scalp_categories = {\n",
        "    \"Doctor Required\": [\"Doctor Required\"],\n",
        "    \"Female\": [\n",
        "        \"Fem Recede Edge\", \"Hair Parting & Thinning Patterns\", \"Patchy Hair Loss\",\n",
        "        \"Scalp Thinning Conditions\", \"Scalp Thinning Conditions Stage 2\", \"Scalp Thinning Conditions Stage 3\"\n",
        "    ],\n",
        "    \"Male\": [\n",
        "        \"Stage 1\", \"Stage 2\", \"Stage 3\", \"Stage 4\", \"Stage 5\", \"Stage 6\", \"Stage 7\", \"Random Patches\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Define recommendations for each scalp category\n",
        "recommendations = {\n",
        "    \"Stage 1\": {\n",
        "        \"food\": [\"Spinach\", \"Carrots\", \"Salmon\", \"Almonds\"],\n",
        "        \"exercise\": [\"Yoga\", \"Neck Stretching\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example1\"],\n",
        "        \"products\": [\"Herbal Shampoo\", \"Scalp Nourishing Oil\"],\n",
        "        \"tips\": \"Use mild shampoo, avoid excessive heat styling.\"\n",
        "    },\n",
        "    \"Stage 2\": {\n",
        "        \"food\": [\"Eggs\", \"Avocados\", \"Berries\", \"Walnuts\"],\n",
        "        \"exercise\": [\"Scalp Massage\", \"Neck Tilts\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example2\"],\n",
        "        \"products\": [\"Hydrating Hair Serum\", \"Anti-Hair Fall Shampoo\"],\n",
        "        \"tips\": \"Avoid tight hairstyles, ensure adequate hydration.\"\n",
        "    },\n",
        "    \"Stage 3\": {\n",
        "        \"food\": [\"Sweet Potatoes\", \"Flaxseeds\", \"Greek Yogurt\", \"Pumpkin Seeds\"],\n",
        "        \"exercise\": [\"Aerobic Exercises\", \"Acupressure Therapy\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example3\"],\n",
        "        \"products\": [\"Deep Repair Hair Mask\", \"Nourishing Hair Oil\"],\n",
        "        \"tips\": \"Increase protein intake, avoid excessive chemical treatments.\"\n",
        "    },\n",
        "    \"Stage 4\": {\n",
        "        \"food\": [\"Lentils\", \"Brazil Nuts\", \"Sunflower Seeds\", \"Milk\"],\n",
        "        \"exercise\": [\"Strength Training\", \"Light Cardio\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example8\"],\n",
        "        \"products\": [\"Scalp Stimulant Oil\", \"Revitalizing Hair Serum\"],\n",
        "        \"tips\": \"Reduce stress, maintain a healthy sleep cycle.\"\n",
        "    },\n",
        "    \"Stage 5\": {\n",
        "        \"food\": [\"Oats\", \"Lean Meats\", \"Soy Protein\", \"Dark Chocolate\"],\n",
        "        \"exercise\": [\"Headstand (with caution)\", \"Breathing Exercises\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example9\"],\n",
        "        \"products\": [\"Keratin Boost Shampoo\", \"DHT Blocker Supplement\"],\n",
        "        \"tips\": \"Limit alcohol consumption, increase hydration.\"\n",
        "    },\n",
        "    \"Stage 6\": {\n",
        "        \"food\": [\"Zinc-rich Foods\", \"Coconut Water\", \"Citrus Fruits\"],\n",
        "        \"exercise\": [\"Relaxation Therapy\", \"Scalp Rolling\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example10\"],\n",
        "        \"products\": [\"Hair Growth Oil\", \"Vitamin-Enriched Hair Mask\"],\n",
        "        \"tips\": \"Reduce inflammation, consume more antioxidants.\"\n",
        "    },\n",
        "    \"Stage 7\": {\n",
        "        \"food\": [\"Whole Grains\", \"Omega-3 Foods\", \"Green Tea\"],\n",
        "        \"exercise\": [\"Light Stretching\", \"Acupressure\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example11\"],\n",
        "        \"products\": [\"Intensive Hair Regrowth Kit\"],\n",
        "        \"tips\": \"Consult a specialist for advanced treatment options.\"\n",
        "    },\n",
        "    \"Random Patches\": {\n",
        "        \"food\": [\"Chia Seeds\", \"Green Tea\", \"Turmeric\", \"Almonds\"],\n",
        "        \"exercise\": [\"Scalp Massage\", \"Breathing Exercises\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example4\"],\n",
        "        \"products\": [\"Hair Rejuvenation Serum\", \"Anti-Hair Fall Kit\"],\n",
        "        \"tips\": \"Increase iron intake, consult a dermatologist if worsening.\"\n",
        "    },\n",
        "    \"Fem Recede Edge\": {\n",
        "        \"food\": [\"Soybeans\", \"Avocados\", \"Nuts\", \"Eggs\"],\n",
        "        \"exercise\": [\"Scalp Stimulation Exercises\", \"Neck Rolls\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example5\"],\n",
        "        \"products\": [\"Hair Strengthening Serum\", \"Biotin Shampoo\"],\n",
        "        \"tips\": \"Avoid harsh chemical treatments, ensure scalp hydration.\"\n",
        "    },\n",
        "    \"Hair Parting & Thinning Patterns\": {\n",
        "        \"food\": [\"Nuts\", \"Eggs\", \"Milk\", \"Leafy Greens\"],\n",
        "        \"exercise\": [\"Scalp Massage\", \"Towel Scrubbing\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example12\"],\n",
        "        \"products\": [\"Volume Boost Shampoo\", \"Thickening Hair Serum\"],\n",
        "        \"tips\": \"Use sulfate-free shampoo, maintain a balanced diet.\"\n",
        "    },\n",
        "    \"Patchy Hair Loss\": {\n",
        "        \"food\": [\"Protein-rich Foods\", \"Dark Leafy Greens\", \"Vitamin C Foods\"],\n",
        "        \"exercise\": [\"Gentle Hair Brushing\", \"Relaxation Therapy\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example6\"],\n",
        "        \"products\": [\"Anti-Patchy Hair Serum\", \"Hair Growth Boost Tonic\"],\n",
        "        \"tips\": \"Monitor scalp conditions, consult a specialist if severe.\"\n",
        "    },\n",
        "    \"Doctor Required\": {\n",
        "        \"food\": [\"Consult a specialist for personalized diet.\"],\n",
        "        \"exercise\": [\"Consult a specialist before exercises.\"],\n",
        "        \"youtube_links\": [\"https://www.youtube.com/watch?v=example7\"],\n",
        "        \"products\": [\"Prescription-based solutions\"],\n",
        "        \"tips\": \"Immediate medical attention is recommended.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Define a default recommendation for unknown scalp conditions\n",
        "default_recommendation = {\n",
        "    \"food\": [\"Consult a specialist for personalized diet.\"],\n",
        "    \"exercise\": [\"Consult a specialist before exercises.\"],\n",
        "    \"youtube_links\": [\"https://www.youtube.com/watch?v=example7\"],\n",
        "    \"products\": [\"General Hair Care Products\"],  # Provide a generic product suggestion\n",
        "    \"tips\": \"Maintain a healthy lifestyle, consult a specialist if concerned.\"\n",
        "}\n",
        "# Function to generate additional risk factor recommendations\n",
        "def generate_risk_factor_recommendations(row):\n",
        "    risk_recommendations = []\n",
        "    if row.get(\"Genetics\") == \"Yes\":\n",
        "        risk_recommendations.append(\"Consider genetic testing for personalized treatments.\")\n",
        "    if row.get(\"Hormonal Changes\") == \"Yes\":\n",
        "        risk_recommendations.append(\"Balance hormones with diet (rich in Omega-3 and Zinc).\")\n",
        "    if row.get(\"Stress\") == \"Yes\":\n",
        "        risk_recommendations.append(\"Practice meditation and deep breathing for stress control.\")\n",
        "    if row.get(\"Smoking\") == \"Yes\":\n",
        "        risk_recommendations.append(\"Quit smoking to improve blood circulation to the scalp.\")\n",
        "    return risk_recommendations\n",
        "\n",
        "# Function to determine scalp condition from folder structure\n",
        "def get_scalp_condition(user_id):\n",
        "    for category, subcategories in scalp_categories.items():\n",
        "        category_path = os.path.join(scalp_folder, category)\n",
        "        if os.path.exists(category_path):\n",
        "            for subcategory in subcategories:\n",
        "                subcategory_path = os.path.join(category_path, subcategory)\n",
        "                if os.path.exists(subcategory_path):\n",
        "                    images = os.listdir(subcategory_path)\n",
        "                    if any(str(user_id) in img for img in images):\n",
        "                        return subcategory\n",
        "    return \"Unknown\"\n",
        "# Generate recommendations for each user and save to a file\n",
        "def save_recommendations_to_drive(df, filename=\"recommendations.txt\"):\n",
        "    \"\"\"Generates recommendations for each user and saves them to a file in Google Drive.\"\"\"\n",
        "    output_path = os.path.join(\"/content/drive/MyDrive/\", filename)  # Path to save the file\n",
        "\n",
        "    with open(output_path, \"w\") as f:\n",
        "        for index, row in df.iterrows():\n",
        "            user_id = row.get(\"User_ID\", index + 1)\n",
        "            scalp_condition = row[\"Scalp_Condition\"]\n",
        "\n",
        "            recs = recommendations.get(scalp_condition, default_recommendation)\n",
        "            risk_recs = generate_risk_factor_recommendations(row)\n",
        "\n",
        "            f.write(f\"\\n--- Recommendations for User {user_id} ({scalp_condition}) ---\\n\")\n",
        "            f.write(f\"Food Suggestions: {', '.join(recs['food'])}\\n\")\n",
        "            f.write(f\"Exercise Suggestions: {', '.join(recs['exercise'])}\\n\")\n",
        "            f.write(f\"Exercise Videos: {', '.join(recs['youtube_links'])}\\n\")\n",
        "            f.write(f\"Recommended AyurGenix Products: {', '.join(recs['products'])}\\n\")\n",
        "            f.write(f\"Hair Care Tips: {recs['tips']}\\n\")\n",
        "\n",
        "            if risk_recs:\n",
        "                f.write(\"Additional Tips Based on Questionnaire:\\n\")\n",
        "                for tip in risk_recs:\n",
        "                    f.write(f\"   - {tip}\\n\")\n",
        "\n",
        "    print(f\"Recommendations saved to: {output_path}\")\n",
        "\n",
        "# ... (after all your other code) ...\n",
        "\n",
        "# Call the function to save the recommendations\n",
        "df[\"Scalp_Condition\"] = df.index.map(lambda i: get_scalp_condition(i+1))\n",
        "save_recommendations_to_drive(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ehkm7KgMmDo",
        "outputId": "8a08b5cd-cfbd-4594-8d74-504ecef0c5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations saved to: /content/drive/MyDrive/recommendations.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Rj154F2iONtNcZryvC0-7Go2kt5xaEnQ",
      "authorship_tag": "ABX9TyM+tyI3VhZZta1Q+Ceyy6PN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}